# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GitPrompt

–ü–æ–¥—Ä–æ–±–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ GitPrompt –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã](#–±–∞–∑–æ–≤—ã–µ-–ø—Ä–∏–º–µ—Ä—ã)
2. [–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏](#–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ-—Å—Ü–µ–Ω–∞—Ä–∏–∏)
3. [–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏](#–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è-—Å-–≤–Ω–µ—à–Ω–∏–º–∏-—Å–∏—Å—Ç–µ–º–∞–º–∏)
4. [–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏](#–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è-–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
5. [–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞](#–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥-–∏-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞)

## –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: –ü—Ä–æ—Å—Ç–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏ –ø–æ–∏—Å–∫

```python
import asyncio
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    VectorDBType,
    LLMProvider,
)

async def basic_example():
    """–ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏ –ø–æ–∏—Å–∫–∞."""
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = Config(
        vector_db=VectorDBConfig(
            type=VectorDBType.CHROMA,
            collection_name="basic_example"
        ),
        llm=LLMConfig(
            provider=LLMProvider.OPENAI,
            api_key="your-openai-api-key",
            model_name="text-embedding-ada-002"
        )
    )
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å–µ—Ä
    indexer = GitIndexer(config)
    
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
    print("üîç –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π...")
    result = await indexer.index_repository("/path/to/your/repo")
    
    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
    print(f"   üìÅ –§–∞–π–ª–æ–≤: {result['total_files']}")
    print(f"   üìÑ –ß–∞–Ω–∫–æ–≤: {result['total_chunks']}")
    print(f"   üß† –≠–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {result['total_embeddings']}")
    
    # –ò—â–µ–º –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
    print("\nüîç –ò—â–µ–º '—Ñ—É–Ω–∫—Ü–∏—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏'...")
    results = await indexer.search_across_repositories(
        "—Ñ—É–Ω–∫—Ü–∏—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏",
        limit=5
    )
    
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    for i, result in enumerate(results, 1):
        print(f"\n{i}. üìÑ {result['file_path']}")
        print(f"   üìä –°—Ö–æ–∂–µ—Å—Ç—å: {result['distance']:.3f}")
        print(f"   üìù –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: {result['content'][:150]}...")

if __name__ == "__main__":
    asyncio.run(basic_example())
```

### –ü—Ä–∏–º–µ—Ä 2: –†–∞–±–æ—Ç–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏

```python
import asyncio
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    VectorDBType,
    LLMProvider,
)

async def multi_repo_example():
    """–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏."""
    
    config = Config(
        vector_db=VectorDBConfig(
            type=VectorDBType.CHROMA,
            collection_name="multi_repo_search"
        ),
        llm=LLMConfig(
            provider=LLMProvider.OPENAI,
            api_key="your-api-key"
        )
    )
    
    indexer = GitIndexer(config)
    
    # –°–ø–∏—Å–æ–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    repositories = [
        "/path/to/frontend-repo",
        "/path/to/backend-repo", 
        "/path/to/mobile-repo",
        "/path/to/docs-repo"
    ]
    
    print("üöÄ –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")
    
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
    total_files = 0
    for repo_path in repositories:
        print(f"\nüìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {repo_path}")
        try:
            result = await indexer.index_repository(repo_path)
            total_files += result['total_files']
            print(f"   ‚úÖ {result['total_files']} —Ñ–∞–π–ª–æ–≤, {result['total_chunks']} —á–∞–Ω–∫–æ–≤")
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    print(f"\nüìä –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {total_files} —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ")
    
    # –ò—â–µ–º –ø–æ –≤—Å–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º
    print("\nüîç –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º...")
    results = await indexer.search_across_repositories(
        "–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
        limit=10
    )
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º
    by_repo = {}
    for result in results:
        repo_path = result.get('repository_path', 'unknown')
        if repo_path not in by_repo:
            by_repo[repo_path] = []
        by_repo[repo_path].append(result)
    
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    for repo_path, repo_results in by_repo.items():
        print(f"\nüìÅ {repo_path}: {len(repo_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        for result in repo_results[:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-2
            print(f"   ‚Ä¢ {result['file_path']} (—Å—Ö–æ–∂–µ—Å—Ç—å: {result['distance']:.3f})")

if __name__ == "__main__":
    asyncio.run(multi_repo_example())
```

### –ü—Ä–∏–º–µ—Ä 3: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≤–µ—Ç–∫–∏

```python
import asyncio
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    VectorDBType,
    LLMProvider,
)

async def branch_indexing_example():
    """–ü—Ä–∏–º–µ—Ä –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≤–µ—Ç–∫–∏."""
    
    config = Config(
        vector_db=VectorDBConfig(
            type=VectorDBType.CHROMA,
            collection_name="branch_analysis"
        ),
        llm=LLMConfig(
            provider=LLMProvider.OPENAI,
            api_key="your-api-key"
        )
    )
    
    indexer = GitIndexer(config)
    repo_path = "/path/to/your/repo"
    
    # –°–ø–∏—Å–æ–∫ –≤–µ—Ç–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    branches = ["main", "develop", "feature/auth", "feature/payments"]
    
    print("üåø –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–µ—Ç–∫–∏...")
    
    for branch in branches:
        print(f"\nüìã –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤–µ—Ç–∫—É: {branch}")
        try:
            result = await indexer.index_repository(repo_path, branch)
            print(f"   ‚úÖ {result['total_files']} —Ñ–∞–π–ª–æ–≤, {result['total_chunks']} —á–∞–Ω–∫–æ–≤")
            
            # –ò—â–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –≤–µ—Ç–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            if branch.startswith("feature/"):
                feature_name = branch.replace("feature/", "")
                results = await indexer.search_across_repositories(
                    f"—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {feature_name}",
                    limit=3
                )
                print(f"   üîç –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤–µ—Ç–∫–∏ {branch}: {e}")

if __name__ == "__main__":
    asyncio.run(branch_indexing_example())
```

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏

### –ü—Ä–∏–º–µ—Ä 4: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

```python
import asyncio
import signal
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    DeploymentConfig,
    VectorDBType,
    LLMProvider,
)

class RealTimeMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏."""
    
    def __init__(self):
        self.config = Config(
            vector_db=VectorDBConfig(
                type=VectorDBType.CHROMA,
                collection_name="realtime_monitor"
            ),
            llm=LLMConfig(
                provider=LLMProvider.OPENAI,
                api_key="your-api-key"
            ),
            deployment=DeploymentConfig(
                enabled=True,
                auto_deploy=True,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
                sync_interval=30   # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
            )
        )
        self.indexer = GitIndexer(self.config)
        self.running = False
    
    async def start_monitoring(self, repo_paths):
        """–ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
        self.running = True
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
        for repo_path in repo_paths:
            print(f"üìÅ –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {repo_path}")
            await self.indexer.add_repository(repo_path)
        
        print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π...")
        print("üí° –ò–∑–º–µ–Ω–µ–Ω–∏—è –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è")
        print("‚èπÔ∏è –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤
        def signal_handler(signum, frame):
            print("\n‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏...")
            self.running = False
        
        signal.signal(signal.SIGINT, signal_handler)
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
            await self.indexer.start_monitoring()
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥...")
            await self.indexer.stop_monitoring()
            self.running = False
    
    async def search_with_notifications(self, query):
        """–ü–æ–∏—Å–∫ —Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏ –æ –Ω–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö."""
        print(f"üîç –ü–æ–∏—Å–∫: '{query}'")
        
        initial_results = await self.indexer.search_across_repositories(query, limit=5)
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(initial_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for i, result in enumerate(initial_results, 1):
            print(f"  {i}. {result['file_path']} (—Å—Ö–æ–∂–µ—Å—Ç—å: {result['distance']:.3f})")
        
        return initial_results

async def main():
    monitor = RealTimeMonitor()
    
    # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    repos = [
        "/path/to/active/project1",
        "/path/to/active/project2"
    ]
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    await monitor.start_monitoring(repos)

if __name__ == "__main__":
    asyncio.run(main())
```

### –ü—Ä–∏–º–µ—Ä 5: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ç–æ–∫ –∏ –∞–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

```python
import asyncio
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    VectorDBType,
    LLMProvider,
)
from gitprompt.interfaces import ChangeType

async def branch_comparison_example():
    """–ü—Ä–∏–º–µ—Ä —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤–µ—Ç–æ–∫ –∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π."""
    
    config = Config(
        vector_db=VectorDBConfig(
            type=VectorDBType.CHROMA,
            collection_name="branch_comparison"
        ),
        llm=LLMConfig(
            provider=LLMProvider.OPENAI,
            api_key="your-api-key"
        )
    )
    
    indexer = GitIndexer(config)
    repo = await indexer.add_repository("/path/to/your/repo")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤–µ—Ç–∫–∏
    base_branch = "main"
    feature_branch = "feature/new-feature"
    
    print(f"üîÑ –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤–µ—Ç–∫–∏: {base_branch} ‚Üî {feature_branch}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–µ–∂–¥—É –≤–µ—Ç–∫–∞–º–∏
    changes = await repo.parser.get_changes(repo.path, base_branch, feature_branch)
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(changes)} –∏–∑–º–µ–Ω–µ–Ω–∏–π:")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π
    change_stats = {
        ChangeType.ADDED: 0,
        ChangeType.MODIFIED: 0,
        ChangeType.DELETED: 0,
        ChangeType.RENAMED: 0
    }
    
    for change in changes:
        change_stats[change.change_type] += 1
        print(f"  {change.change_type.value}: {change.file_path}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º diff –¥–ª—è –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if change.change_type == ChangeType.MODIFIED and change.diff:
            print(f"    üìù Diff: {change.diff[:200]}...")
    
    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π:")
    for change_type, count in change_stats.items():
        if count > 0:
            print(f"  {change_type.value}: {count} —Ñ–∞–π–ª–æ–≤")
    
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
    print(f"\nüîç –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è...")
    result = await repo.index_changes(changes)
    
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:")
    print(f"  üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result['processed_files']}")
    print(f"  ‚ûï –ù–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤: {result['new_chunks']}")
    print(f"  üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {result['updated_chunks']}")
    print(f"  ‚ûñ –£–¥–∞–ª–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {result['deleted_chunks']}")
    
    # –ò—â–µ–º –ø–æ –Ω–æ–≤—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏—è–º
    print(f"\nüîç –ü–æ–∏—Å–∫ –ø–æ –Ω–æ–≤—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏—è–º...")
    new_feature_results = await repo.search_similar(
        "–Ω–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å",
        limit=5
    )
    
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(new_feature_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:")
    for result in new_feature_results:
        print(f"  ‚Ä¢ {result['file_path']} (—Å—Ö–æ–∂–µ—Å—Ç—å: {result['distance']:.3f})")

if __name__ == "__main__":
    asyncio.run(branch_comparison_example())
```

### –ü—Ä–∏–º–µ—Ä 6: –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞

```python
import asyncio
from collections import defaultdict
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    VectorDBType,
    LLMProvider,
)

async def architecture_analysis_example():
    """–ü—Ä–∏–º–µ—Ä –∞–Ω–∞–ª–∏–∑–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞."""
    
    config = Config(
        vector_db=VectorDBConfig(
            type=VectorDBType.CHROMA,
            collection_name="architecture_analysis"
        ),
        llm=LLMConfig(
            provider=LLMProvider.OPENAI,
            api_key="your-api-key"
        )
    )
    
    indexer = GitIndexer(config)
    repo = await indexer.add_repository("/path/to/your/project")
    
    print("üèóÔ∏è –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞")
    print("=" * 50)
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    architecture_patterns = {
        "üåê API Layer": [
            "REST API endpoints",
            "GraphQL resolvers",
            "HTTP handlers",
            "route definitions",
            "API controllers"
        ],
        "üóÑÔ∏è Database Layer": [
            "database models",
            "ORM entities",
            "database migrations",
            "SQL queries",
            "database connections"
        ],
        "üîê Authentication": [
            "user authentication",
            "JWT tokens",
            "OAuth implementation",
            "session management",
            "authorization"
        ],
        "üíº Business Logic": [
            "service classes",
            "business rules",
            "domain models",
            "use cases",
            "application services"
        ],
        "‚öôÔ∏è Configuration": [
            "environment variables",
            "configuration files",
            "settings management",
            "feature flags",
            "app configuration"
        ],
        "üß™ Testing": [
            "unit tests",
            "integration tests",
            "test fixtures",
            "mock objects",
            "test utilities"
        ]
    }
    
    architecture_map = defaultdict(list)
    
    for category, patterns in architecture_patterns.items():
        print(f"\n{category}:")
        
        for pattern in patterns:
            results = await repo.search_similar(pattern, limit=3)
            
            if results:
                print(f"  ‚úÖ '{pattern}': {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                for result in results:
                    architecture_map[category].append(result)
                    print(f"    ‚Ä¢ {result['file_path']} (—Å—Ö–æ–∂–µ—Å—Ç—å: {result['distance']:.3f})")
            else:
                print(f"  ‚ùå '{pattern}': –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –°–≤–æ–¥–∫–∞ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
    print(f"\nüìä –°–≤–æ–¥–∫–∞ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ:")
    for category, files in architecture_map.items():
        unique_files = set(result['file_path'] for result in files)
        print(f"  {category}: {len(unique_files)} —Ñ–∞–π–ª–æ–≤")
    
    # –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
    print(f"\n‚ö†Ô∏è –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º:")
    problem_patterns = [
        "TODO comments",
        "FIXME comments",
        "deprecated functions",
        "hardcoded values",
        "security vulnerabilities",
        "performance issues"
    ]
    
    for pattern in problem_patterns:
        results = await repo.search_similar(pattern, limit=2)
        if results:
            print(f"  üö® {pattern}: {len(results)} –Ω–∞–π–¥–µ–Ω–æ")
            for result in results:
                print(f"    ‚Ä¢ {result['file_path']}")
    
    # –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    print(f"\nüîó –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:")
    dependency_patterns = [
        "import statements",
        "require statements",
        "dependency injection",
        "module imports"
    ]
    
    for pattern in dependency_patterns:
        results = await repo.search_similar(pattern, limit=2)
        if results:
            print(f"  üì¶ {pattern}: {len(results)} –Ω–∞–π–¥–µ–Ω–æ")

if __name__ == "__main__":
    asyncio.run(architecture_analysis_example())
```

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏

### –ü—Ä–∏–º–µ—Ä 7: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CI/CD

```python
import asyncio
import os
import json
from datetime import datetime
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    DeploymentConfig,
    DeploymentManager,
    VectorDBType,
    LLMProvider,
)

async def ci_cd_integration_example():
    """–ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å CI/CD pipeline."""
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è CI/CD
    repo_path = os.getenv("CI_PROJECT_DIR", "/workspace")
    branch = os.getenv("CI_COMMIT_REF_NAME", "main")
    commit_sha = os.getenv("CI_COMMIT_SHA", "unknown")
    pipeline_id = os.getenv("CI_PIPELINE_ID", "unknown")
    
    print(f"üöÄ CI/CD –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è")
    print(f"  üìÅ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {repo_path}")
    print(f"  üåø –í–µ—Ç–∫–∞: {branch}")
    print(f"  üîó –ö–æ–º–º–∏—Ç: {commit_sha}")
    print(f"  üîÑ Pipeline: {pipeline_id}")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è CI/CD
    config = Config(
        vector_db=VectorDBConfig(
            type=VectorDBType.PINECONE,
            api_key=os.getenv("PINECONE_API_KEY"),
            collection_name=f"ci-{pipeline_id}-{branch.replace('/', '-')}"
        ),
        llm=LLMConfig(
            provider=LLMProvider.OPENAI,
            api_key=os.getenv("OPENAI_API_KEY"),
            model_name="text-embedding-3-large"  # –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è CI/CD
        ),
        deployment=DeploymentConfig(
            enabled=True,
            server_url=os.getenv("INDEXING_SERVER_URL"),
            api_key=os.getenv("INDEXING_SERVER_KEY"),
            auto_deploy=True
        ),
        max_workers=8  # –ë–æ–ª—å—à–µ –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è CI/CD
    )
    
    indexer = GitIndexer(config)
    
    try:
        start_time = datetime.now()
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –≤–µ—Ç–∫—É
        print(f"\nüîç –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é...")
        result = await indexer.index_repository(repo_path, branch)
        
        end_time = datetime.now()
        indexing_time = (end_time - start_time).total_seconds()
        
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {indexing_time:.2f} —Å–µ–∫—É–Ω–¥:")
        print(f"  üìÅ –§–∞–π–ª–æ–≤: {result['total_files']}")
        print(f"  üìÑ –ß–∞–Ω–∫–æ–≤: {result['total_chunks']}")
        print(f"  üß† –≠–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {result['total_embeddings']}")
        
        # –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–µ–º –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
        if config.deployment.enabled:
            print(f"\nüåê –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–µ–º –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ...")
            deployment_manager = DeploymentManager(config.deployment, indexer)
            await deployment_manager.initialize()
            
            deploy_result = await deployment_manager.deploy_repository(repo_path)
            print(f"‚úÖ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ: {deploy_result}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏...")
        test_queries = [
            "main entry point",
            "configuration setup",
            "error handling",
            "database connection",
            "API endpoints"
        ]
        
        test_results = {}
        for query in test_queries:
            results = await indexer.search_across_repositories(query, limit=1)
            test_results[query] = len(results) > 0
            status = "‚úÖ" if len(results) > 0 else "‚ùå"
            print(f"  {status} '{query}': {'–Ω–∞–π–¥–µ–Ω–æ' if len(results) > 0 else '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "pipeline_id": pipeline_id,
            "branch": branch,
            "commit_sha": commit_sha,
            "indexing_time_seconds": indexing_time,
            "total_files": result['total_files'],
            "total_chunks": result['total_chunks'],
            "total_embeddings": result['total_embeddings'],
            "test_results": test_results,
            "deployment_success": config.deployment.enabled
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ñ–∞–π–ª
        metrics_file = f"/tmp/ci_metrics_{pipeline_id}.json"
        with open(metrics_file, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {metrics_file}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ (–ø—Ä–∏–º–µ—Ä)
        if os.getenv("SLACK_WEBHOOK_URL"):
            await send_slack_notification(metrics)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
        # –í CI/CD –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å exit code
        exit(1)

async def send_slack_notification(metrics):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Slack."""
    import aiohttp
    
    webhook_url = os.getenv("SLACK_WEBHOOK_URL")
    if not webhook_url:
        return
    
    message = {
        "text": f"üöÄ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞",
        "attachments": [
            {
                "color": "good",
                "fields": [
                    {"title": "Pipeline", "value": metrics["pipeline_id"], "short": True},
                    {"title": "–í–µ—Ç–∫–∞", "value": metrics["branch"], "short": True},
                    {"title": "–§–∞–π–ª–æ–≤", "value": str(metrics["total_files"]), "short": True},
                    {"title": "–í—Ä–µ–º—è", "value": f"{metrics['indexing_time_seconds']:.2f}s", "short": True}
                ]
            }
        ]
    }
    
    async with aiohttp.ClientSession() as session:
        async with session.post(webhook_url, json=message) as response:
            if response.status == 200:
                print("üì± –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Slack")

if __name__ == "__main__":
    asyncio.run(ci_cd_integration_example())
```

### –ü—Ä–∏–º–µ—Ä 8: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Jupyter Notebook

```python
# –í Jupyter Notebook
import asyncio
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    VectorDBType,
    LLMProvider,
)
import pandas as pd
import matplotlib.pyplot as plt

class GitPromptNotebook:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GitPrompt –≤ Jupyter Notebook."""
    
    def __init__(self, config):
        self.config = config
        self.indexer = GitIndexer(config)
        self.results_cache = {}
    
    async def analyze_repository(self, repo_path):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π."""
        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {repo_path}")
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
        result = await self.indexer.index_repository(repo_path)
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        data = {
            '–ú–µ—Ç—Ä–∏–∫–∞': ['–§–∞–π–ª—ã', '–ß–∞–Ω–∫–∏', '–≠–º–±–µ–¥–¥–∏–Ω–≥–∏'],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': [result['total_files'], result['total_chunks'], result['total_embeddings']]
        }
        df = pd.DataFrame(data)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # –°—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
        df.plot(x='–ú–µ—Ç—Ä–∏–∫–∞', y='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', kind='bar', ax=ax1, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
        ax1.set_title('–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏')
        ax1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        
        # –ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
        ax2.pie(df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'], labels=df['–ú–µ—Ç—Ä–∏–∫–∞'], autopct='%1.1f%%', startangle=90)
        ax2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º')
        
        plt.tight_layout()
        plt.show()
        
        return result
    
    async def search_and_visualize(self, query, limit=10):
        """–ü–æ–∏—Å–∫ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        print(f"üîç –ò—â–µ–º: '{query}'")
        
        results = await self.indexer.search_across_repositories(query, limit)
        
        if not results:
            print("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        data = []
        for result in results:
            data.append({
                '–§–∞–π–ª': result['file_path'],
                '–°—Ö–æ–∂–µ—Å—Ç—å': result['distance'],
                '–°–æ–¥–µ—Ä–∂–∏–º–æ–µ': result['content'][:100] + '...'
            })
        
        df = pd.DataFrame(data)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
        plt.figure(figsize=(12, 6))
        plt.barh(range(len(df)), df['–°—Ö–æ–∂–µ—Å—Ç—å'], color='skyblue')
        plt.yticks(range(len(df)), df['–§–∞–π–ª'])
        plt.xlabel('–°—Ö–æ–∂–µ—Å—Ç—å')
        plt.title(f'–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: "{query}"')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
        display(df)
        
        return df
    
    async def compare_branches_visualization(self, repo_path, branch1, branch2):
        """–í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ç–æ–∫."""
        repo = await self.indexer.add_repository(repo_path)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        changes = await repo.parser.get_changes(repo.path, branch1, branch2)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π
        change_types = {}
        for change in changes:
            change_type = change.change_type.value
            change_types[change_type] = change_types.get(change_type, 0) + 1
        
        # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º
        if change_types:
            plt.figure(figsize=(8, 6))
            plt.pie(change_types.values(), labels=change_types.keys(), autopct='%1.1f%%', startangle=90)
            plt.title(f'–ò–∑–º–µ–Ω–µ–Ω–∏—è –º–µ–∂–¥—É {branch1} –∏ {branch2}')
            plt.show()
        
        return change_types

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ Jupyter Notebook
async def notebook_example():
    config = Config(
        vector_db=VectorDBConfig(
            type=VectorDBType.CHROMA,
            collection_name="notebook_index",
        ),
        llm=LLMConfig(
            provider=LLMProvider.OPENAI,
            api_key="your-key",
        ),
    )
    
    notebook = GitPromptNotebook(config)
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
    result = await notebook.analyze_repository("/path/to/repo")
    
    # –ü–æ–∏—Å–∫ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    df = await notebook.search_and_visualize("—Ñ—É–Ω–∫—Ü–∏—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ç–æ–∫
    changes = await notebook.compare_branches_visualization(
        "/path/to/repo", "main", "feature/new"
    )

# –ó–∞–ø—É—Å–∫ –≤ Jupyter
# await notebook_example()
```

## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –ü—Ä–∏–º–µ—Ä 9: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤

```python
import asyncio
import time
import psutil
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    VectorDBType,
    LLMProvider,
)

class PerformanceOptimizedIndexer:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å–µ—Ä –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤."""
    
    def __init__(self):
        self.config = Config(
            vector_db=VectorDBConfig(
                type=VectorDBType.CHROMA,
                collection_name="large_repo_optimized"
            ),
            llm=LLMConfig(
                provider=LLMProvider.OPENAI,
                api_key="your-key",
                model_name="text-embedding-3-small",  # –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
                batch_size=200,  # –ë–æ–ª—å—à–∏–µ –±–∞—Ç—á–∏
                max_tokens=8192
            ),
            git=GitConfig(
                chunk_size=800,  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
                chunk_overlap=150
            ),
            max_workers=8,  # –ú–Ω–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–æ–≤
            cache_dir="/tmp/gitprompt_cache"
        )
        self.indexer = GitIndexer(self.config)
    
    def monitor_resources(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤ —Å–∏—Å—Ç–µ–º—ã."""
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        cpu_percent = process.cpu_percent()
        
        print(f"üìä –†–µ—Å—É—Ä—Å—ã —Å–∏—Å—Ç–µ–º—ã:")
        print(f"  üíæ –ü–∞–º—è—Ç—å: {memory_mb:.2f} MB")
        print(f"  üñ•Ô∏è CPU: {cpu_percent:.1f}%")
        
        return memory_mb, cpu_percent
    
    async def index_large_repo_optimized(self, repo_path):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±–æ–ª—å—à–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è."""
        print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é: {repo_path}")
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º —Ä–µ—Å—É—Ä—Å—ã –¥–æ –Ω–∞—á–∞–ª–∞
        initial_memory, initial_cpu = self.monitor_resources()
        
        start_time = time.time()
        
        try:
            # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
            result = await self.indexer.index_repository(repo_path)
            
            end_time = time.time()
            total_time = end_time - start_time
            
            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º —Ä–µ—Å—É—Ä—Å—ã –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            final_memory, final_cpu = self.monitor_resources()
            
            print(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            print(f"  üìÅ –§–∞–π–ª–æ–≤: {result['total_files']}")
            print(f"  üìÑ –ß–∞–Ω–∫–æ–≤: {result['total_chunks']}")
            print(f"  üß† –≠–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {result['total_embeddings']}")
            print(f"  ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {result['total_files'] / total_time:.2f} —Ñ–∞–π–ª–æ–≤/—Å–µ–∫")
            print(f"  üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {final_memory - initial_memory:.2f} MB")
            
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
            raise
    
    async def batch_search_optimized(self, queries, limit=5):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤—É –∑–∞–ø—Ä–æ—Å–æ–≤."""
        print(f"üîç –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –ø–æ {len(queries)} –∑–∞–ø—Ä–æ—Å–∞–º...")
        
        start_time = time.time()
        results = {}
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = []
        for query in queries:
            task = self.indexer.search_across_repositories(query, limit)
            tasks.append((query, task))
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        for query, task in tasks:
            try:
                result = await task
                results[query] = result
                print(f"  ‚úÖ '{query}': {len(result)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            except Exception as e:
                print(f"  ‚ùå '{query}': –æ—à–∏–±–∫–∞ - {e}")
                results[query] = []
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"‚ö° –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {len(queries) / total_time:.2f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫")
        
        return results

async def performance_example():
    """–ü—Ä–∏–º–µ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    optimizer = PerformanceOptimizedIndexer()
    
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –±–æ–ª—å—à–æ–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
    result = await optimizer.index_large_repo_optimized("/path/to/large/repo")
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
    queries = [
        "database connection",
        "authentication system",
        "error handling",
        "configuration management",
        "API endpoints",
        "business logic",
        "data validation",
        "logging system"
    ]
    
    results = await optimizer.batch_search_optimized(queries, limit=3)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    total_results = sum(len(r) for r in results.values())
    print(f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  üîç –í—Å–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {total_results}")
    print(f"  üìà –°—Ä–µ–¥–Ω–µ–µ –Ω–∞ –∑–∞–ø—Ä–æ—Å: {total_results / len(queries):.1f}")

if __name__ == "__main__":
    asyncio.run(performance_example())
```

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞

### –ü—Ä–∏–º–µ—Ä 10: –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

```python
import asyncio
import json
import time
from datetime import datetime, timedelta
from collections import defaultdict
from gitprompt import (
    GitIndexer,
    Config,
    VectorDBConfig,
    LLMConfig,
    VectorDBType,
    LLMProvider,
)

class GitPromptAnalytics:
    """–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è GitPrompt."""
    
    def __init__(self):
        self.config = Config(
            vector_db=VectorDBConfig(
                type=VectorDBType.CHROMA,
                collection_name="analytics_data"
            ),
            llm=LLMConfig(
                provider=LLMProvider.OPENAI,
                api_key="your-key"
            )
        )
        self.indexer = GitIndexer(self.config)
        self.analytics_data = defaultdict(list)
    
    async def track_search_queries(self, repo_path, duration_hours=24):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤."""
        print(f"üìä –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤ —Ç–µ—á–µ–Ω–∏–µ {duration_hours} —á–∞—Å–æ–≤...")
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–æ –±—ã–ª–∏ –±—ã —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)
        sample_queries = [
            "—Ñ—É–Ω–∫—Ü–∏—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            "–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫",
            "–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
            "API endpoints",
            "—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "–∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"
        ]
        
        end_time = time.time() + (duration_hours * 3600)
        
        while time.time() < end_time:
            # –°–ª—É—á–∞–π–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            import random
            query = random.choice(sample_queries)
            
            start_search = time.time()
            results = await self.indexer.search_across_repositories(query, limit=5)
            search_time = time.time() - start_search
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É
            self.analytics_data['searches'].append({
                'timestamp': datetime.now().isoformat(),
                'query': query,
                'results_count': len(results),
                'search_time': search_time,
                'repo_path': repo_path
            })
            
            print(f"üîç '{query}': {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞ {search_time:.3f}s")
            
            # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
            await asyncio.sleep(60)  # 1 –º–∏–Ω—É—Ç–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    def generate_analytics_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–µ."""
        print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–µ...")
        
        searches = self.analytics_data['searches']
        if not searches:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        query_stats = defaultdict(int)
        total_search_time = 0
        total_results = 0
        
        for search in searches:
            query_stats[search['query']] += 1
            total_search_time += search['search_time']
            total_results += search['results_count']
        
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
        print(f"  üîç –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(searches)}")
        print(f"  ‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {total_search_time / len(searches):.3f}s")
        print(f"  üìã –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {total_results / len(searches):.1f}")
        
        print(f"\nüèÜ –¢–æ–ø-5 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
        sorted_queries = sorted(query_stats.items(), key=lambda x: x[1], reverse=True)
        for i, (query, count) in enumerate(sorted_queries[:5], 1):
            print(f"  {i}. '{query}': {count} —Ä–∞–∑")
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        search_times = [s['search_time'] for s in searches]
        avg_time = sum(search_times) / len(search_times)
        max_time = max(search_times)
        min_time = min(search_times)
        
        print(f"\n‚ö° –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
        print(f"  üìä –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.3f}s")
        print(f"  üêå –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max_time:.3f}s")
        print(f"  üöÄ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min_time:.3f}s")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_searches': len(searches),
            'avg_search_time': avg_time,
            'avg_results': total_results / len(searches),
            'top_queries': dict(sorted_queries[:5]),
            'performance': {
                'avg_time': avg_time,
                'max_time': max_time,
                'min_time': min_time
            }
        }
        
        with open(f'/tmp/analytics_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª")
        
        return report
    
    async def monitor_repository_health(self, repo_path):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–¥–æ—Ä–æ–≤—å—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è."""
        print(f"üè• –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–¥–æ—Ä–æ–≤—å—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {repo_path}")
        
        repo = await self.indexer.add_repository(repo_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã
        health_checks = {
            'indexing_speed': await self._check_indexing_speed(repo),
            'search_quality': await self._check_search_quality(repo),
            'coverage': await self._check_coverage(repo),
            'freshness': await self._check_freshness(repo)
        }
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è:")
        for check, result in health_checks.items():
            status = "‚úÖ" if result['healthy'] else "‚ùå"
            print(f"  {status} {check}: {result['message']}")
        
        return health_checks
    
    async def _check_indexing_speed(self, repo):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."""
        start_time = time.time()
        result = await repo.index_repository()
        end_time = time.time()
        
        speed = result['total_files'] / (end_time - start_time)
        healthy = speed > 10  # –ë–æ–ª—å—à–µ 10 —Ñ–∞–π–ª–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É
        
        return {
            'healthy': healthy,
            'message': f"{speed:.2f} —Ñ–∞–π–ª–æ–≤/—Å–µ–∫",
            'value': speed
        }
    
    async def _check_search_quality(self, repo):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞."""
        test_queries = [
            "main function",
            "error handling",
            "configuration"
        ]
        
        total_results = 0
        for query in test_queries:
            results = await repo.search_similar(query, limit=1)
            total_results += len(results)
        
        avg_results = total_results / len(test_queries)
        healthy = avg_results > 0.5  # –ë–æ–ª—å—à–µ 50% –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–∞—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        
        return {
            'healthy': healthy,
            'message': f"{avg_results:.2f} —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
            'value': avg_results
        }
    
    async def _check_coverage(self, repo):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è —Ñ–∞–π–ª–æ–≤."""
        # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã
        result = await repo.index_repository()
        healthy = result['total_files'] > 10  # –ë–æ–ª—å—à–µ 10 —Ñ–∞–π–ª–æ–≤
        
        return {
            'healthy': healthy,
            'message': f"{result['total_files']} —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ",
            'value': result['total_files']
        }
    
    async def _check_freshness(self, repo):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–∞."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–µ–¥–∞–≤–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        changes = await repo.parser.get_current_changes(repo.path)
        healthy = len(changes) < 5  # –ú–µ–Ω—å—à–µ 5 –Ω–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
        
        return {
            'healthy': healthy,
            'message': f"{len(changes)} –Ω–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π",
            'value': len(changes)
        }

async def analytics_example():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∏."""
    analytics = GitPromptAnalytics()
    
    # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    await analytics.track_search_queries("/path/to/repo", duration_hours=1)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report = analytics.generate_analytics_report()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
    health = await analytics.monitor_repository_health("/path/to/repo")

if __name__ == "__main__":
    asyncio.run(analytics_example())
```

---

–≠—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ GitPrompt, –æ—Ç –ø—Ä–æ—Å—Ç—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –¥–æ —Å–ª–æ–∂–Ω—ã—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏. –ö–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä –≤–∫–ª—é—á–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è.
